{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLM\n",
    "we input a sentence and ask that BERT outputs the same sentence.\n",
    "\n",
    "- Tokenize our text. \n",
    "- Create a labels tensor. We’re training our model here, so we need a labels tensor to calculate loss against — and optimize towards.\n",
    "- Mask tokens in input_ids. The BERT paper uses a 15% probability of masking each token during model pre-training, with a few additional rules — we’ll use a simplified version of this and assign a 15% probability of each word being masked.\n",
    "- Calculate loss. pred=softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "pd.set_option('max_colwidth',300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_files = sorted(Path('./datasets/python/final/jsonl').glob('**/*.gz'))\n",
    "\n",
    "columns_long_list = ['repo', 'path', 'url', 'code', \n",
    "                     'code_tokens', 'docstring', 'docstring_tokens', \n",
    "                     'language', 'partition']\n",
    "\n",
    "columns_short_list = ['code_tokens', 'docstring_tokens', \n",
    "                      'language', 'partition']\n",
    "\n",
    "columns_for_token = ['code_tokens', 'partition']\n",
    "\n",
    "def jsonl_list_to_dataframe(file_list, columns=columns_long_list):\n",
    "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
    "    return pd.concat([pd.read_json(f, \n",
    "                                   orient='records', \n",
    "                                   compression='gzip',\n",
    "                                   lines=True)[columns] \n",
    "                      for f in file_list], sort=False)\n",
    "\n",
    "pydf = jsonl_list_to_dataframe(python_files, columns_for_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412178 23107 22176\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[def, train, (, train_dir, ,, model_save_path, =, None, ,, n_neighbors, =, None, ,, knn_algo, =, 'ball_tree', ,, verbose, =, False, ), :, X, =, [, ], y, =, [, ], # Loop through each person in the training set, for, class_dir, in, os, ., listdir, (, train_dir, ), :, if, not, os, ., path, ., isdir...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[def, predict, (, X_img_path, ,, knn_clf, =, None, ,, model_path, =, None, ,, distance_threshold, =, 0.6, ), :, if, not, os, ., path, ., isfile, (, X_img_path, ), or, os, ., path, ., splitext, (, X_img_path, ), [, 1, ], [, 1, :, ], not, in, ALLOWED_EXTENSIONS, :, raise, Exception, (, \"Invalid im...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[def, show_prediction_labels_on_image, (, img_path, ,, predictions, ), :, pil_image, =, Image, ., open, (, img_path, ), ., convert, (, \"RGB\", ), draw, =, ImageDraw, ., Draw, (, pil_image, ), for, name, ,, (, top, ,, right, ,, bottom, ,, left, ), in, predictions, :, # Draw a box around the face u...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                   code_tokens  \\\n",
       "0  [def, train, (, train_dir, ,, model_save_path, =, None, ,, n_neighbors, =, None, ,, knn_algo, =, 'ball_tree', ,, verbose, =, False, ), :, X, =, [, ], y, =, [, ], # Loop through each person in the training set, for, class_dir, in, os, ., listdir, (, train_dir, ), :, if, not, os, ., path, ., isdir...   \n",
       "1  [def, predict, (, X_img_path, ,, knn_clf, =, None, ,, model_path, =, None, ,, distance_threshold, =, 0.6, ), :, if, not, os, ., path, ., isfile, (, X_img_path, ), or, os, ., path, ., splitext, (, X_img_path, ), [, 1, ], [, 1, :, ], not, in, ALLOWED_EXTENSIONS, :, raise, Exception, (, \"Invalid im...   \n",
       "2  [def, show_prediction_labels_on_image, (, img_path, ,, predictions, ), :, pil_image, =, Image, ., open, (, img_path, ), ., convert, (, \"RGB\", ), draw, =, ImageDraw, ., Draw, (, pil_image, ), for, name, ,, (, top, ,, right, ,, bottom, ,, left, ), in, predictions, :, # Draw a box around the face u...   \n",
       "\n",
       "  partition  \n",
       "0     train  \n",
       "1     train  \n",
       "2     train  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pydf.groupby(\"partition\").filter(lambda df : pd.Series(['train']).isin(df['partition']).all())\n",
    "valid = pydf.groupby(\"partition\").filter(lambda df : pd.Series(['valid']).isin(df['partition']).all())\n",
    "test  = pydf.groupby(\"partition\").filter(lambda df : pd.Series(['test']).isin(df['partition']).all())\n",
    "print(train.shape[0], valid.shape[0], test.shape[0])\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def', 'train', '(', 'train_dir', ',']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['code_tokens'].iloc[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = train['code_tokens'].iloc[:20048] # 取2048个mini样本作为train demo\n",
    "valid_samples = valid['code_tokens'].iloc[:256] # 取256个mini样本作为valid demo\n",
    "test_samples = valid['code_tokens'].iloc[:64] # 取64个mini样本作为test demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove the comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Iterable\n",
    "\n",
    "def is_comment_token(language: str, token: str) -> bool:\n",
    "    len_token = len(token)\n",
    "\n",
    "    if language in ['python', 'ruby', 'php'] and len_token >= 1 and token.startswith('#'):\n",
    "        return True\n",
    "    if language in ['java', 'javascript', 'go', 'php'] \\\n",
    "            and len_token >= 2 and (token.startswith('//') or token.startswith('/*')):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def remove_inline_comments(language: str, code_tokens: List[str]) -> List[str]:\n",
    "    return [token for token in code_tokens if not is_comment_token(language, token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_samples = train_samples.apply(lambda tokens: remove_inline_comments('python', tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin token of 30th is a comment:  # Loop through each person in the training set\n",
      "New token after removing the comment is the keyword 'for':  for\n"
     ]
    }
   ],
   "source": [
    "print(\"Origin token of 30th is a comment: \", train_samples[0][30])\n",
    "print(\"New token after removing the comment is the keyword \\'for\\': \", new_train_samples[0][30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new key words extracted from the code projects, as special token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight torch.Size([30522, 768])\n",
      "['!', '='] [100]\n",
      "['model', '_', 'save', '_', 'path'] [100]\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)\n",
    "    break\n",
    "print(tokenizer.tokenize('!='), tokenizer.convert_tokens_to_ids(['!=']))\n",
    "print(tokenizer.tokenize('model_save_path'), tokenizer.convert_tokens_to_ids(['model_save_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30551, 768)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new tokens\n",
    "for new_tokens in new_train_samples:\n",
    "    num_added_tokens = tokenizer.add_tokens(new_tokens) # (132702, 768)\n",
    "    break\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight torch.Size([30551, 768])\n",
      "['!='] [30537]\n",
      "['model_save_path'] [30523]\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)\n",
    "    break\n",
    "print(tokenizer.tokenize('!='), tokenizer.convert_tokens_to_ids(['!=']))\n",
    "print(tokenizer.tokenize('model_save_path'), tokenizer.convert_tokens_to_ids(['model_save_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(net, tokenizer):\n",
    "    net.save_pretrained('results/bert/')\n",
    "    tokenizer.save_pretrained('results/tokenizer/')\n",
    "# def save_model(net):\n",
    "#     model_name = './results/bert.net'\n",
    "#     checkpoint = {\n",
    "#         'state_dict': net.state_dict()\n",
    "#     }\n",
    "    \n",
    "\n",
    "# #     checkpoint = {'n_hidden': net.n_hidden,\n",
    "# #                 'n_layers': net.n_layers,\n",
    "# #                 'state_dict': net.state_dict(),\n",
    "# #                 'tokens': dictionary,\n",
    "# #                 'int2token': int2token,\n",
    "# #                 'token2int': token2int}\n",
    "\n",
    "#     with open(model_name, 'wb') as f:\n",
    "#         torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./results/tokenizer/')\n",
    "bert = BertForMaskedLM.from_pretrained('./results/bert/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into fixed Chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_method_to_fixed_length(samples, seq_length_max=510):\n",
    "    chunks = []\n",
    "    for i, method in enumerate(samples):\n",
    "#         print(method[:10])\n",
    "        chunks.extend([method[i:i+seq_length_max] for i in range(0, len(method), seq_length_max)]) # split method into chunks\n",
    "#         print(len(chunks)) \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_method_to_fixed_length(new_train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20548\n",
      "234 208 169 30 54 31\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))\n",
    "print(len(chunks[0]), len(chunks[1]), len(chunks[2]), len(chunks[3]), len(chunks[4]), len(chunks[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max chunk length:  510\n",
      "Min chunk length:  1\n"
     ]
    }
   ],
   "source": [
    "max_len = 100\n",
    "min_len = 100\n",
    "\n",
    "for seq in chunks:\n",
    "        # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "#     input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(seq))\n",
    "    \n",
    "    min_len = min(min_len, len(seq))\n",
    "    \n",
    "print('Max chunk length: ', max_len)\n",
    "print('Min chunk length: ', min_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer(text, \n",
    "#                     return_tensors='pt', \n",
    "#                     max_length=512, \n",
    "#                     truncation=True, \n",
    "#                     padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = {\"input_ids\": [], \"token_type_ids\": [], \"attention_mask\": [], \"labels\": []}\n",
    "\n",
    "for chunk in chunks:\n",
    "    \n",
    "    encoding = tokenizer.encode_plus(\n",
    "      chunk,\n",
    "      add_special_tokens=True,\n",
    "      max_length=512, # 510 + [CLS] + [PAD]\n",
    "      return_token_type_ids=True,\n",
    "      padding=\"max_length\",\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    \n",
    "#     encoding['labels'] = encoding.input_ids.detach().clone()\n",
    "#     encodings.append(encoding)\n",
    "\n",
    "    encodings[\"input_ids\"].append(encoding[\"input_ids\"].squeeze())\n",
    "    encodings[\"token_type_ids\"].append(encoding[\"token_type_ids\"].squeeze())\n",
    "    encodings[\"attention_mask\"].append(encoding[\"attention_mask\"].squeeze())\n",
    "    encodings[\"labels\"].append(encoding[\"input_ids\"].squeeze())\n",
    "    \n",
    "# inputs[\"input_ids\"] = torch.cat(encodings[\"input_ids\"], dim=0)\n",
    "encodings[\"input_ids\"] = torch.stack(encodings[\"input_ids\"])\n",
    "encodings[\"token_type_ids\"] = torch.stack(encodings[\"token_type_ids\"])\n",
    "encodings[\"attention_mask\"] = torch.stack(encodings[\"attention_mask\"])\n",
    "encodings[\"labels\"] = torch.stack(encodings[\"labels\"])\n",
    "encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20548, 512]) torch.Size([20548, 512]) torch.Size([20548, 512]) torch.Size([20548, 512])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(encodings[\"input_ids\"].shape, encodings[\"token_type_ids\"].shape, encodings[\"attention_mask\"].shape, encodings[\"labels\"].shape)\n",
    "print(type(encodings['input_ids']), type(encodings['token_type_ids']), type(encodings['attention_mask']), type(encodings['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101, 13366,   100,  1006,  2969,  1010,  5950,  1027,   100,  1006,\n",
      "         1007,  1007,  1024,  2065,  2969,  1012,   100,   100,  2969,  1012,\n",
      "          100,  1024,  2709,  2969,  1012,   100,  2842,  1024,  2709,  2969,\n",
      "         1012,   100,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(encoding[\"input_ids\"].squeeze()[:100])\n",
    "print(encoding[\"attention_mask\"].squeeze()[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(encodings[\"input_ids\"].shape)\n",
    "# create mask array for mlm task\n",
    "mask_arr = (rand < 0.15) * (encodings[\"input_ids\"] != 101) * \\\n",
    "           (encodings[\"input_ids\"] != 102) * (encodings[\"input_ids\"] != 0)\n",
    "selection = []\n",
    "\n",
    "for i in range(encodings[\"input_ids\"].shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero(as_tuple=False)).tolist()\n",
    "    )\n",
    "    \n",
    "for i in range(encodings[\"input_ids\"].shape[0]):\n",
    "    encodings[\"input_ids\"][i, selection[i]] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n",
      "torch.Size([20548, 512])\n",
      "token_type_ids\n",
      "torch.Size([20548, 512])\n",
      "attention_mask\n",
      "torch.Size([20548, 512])\n",
      "labels\n",
      "torch.Size([20548, 512])\n"
     ]
    }
   ],
   "source": [
    "for key, val in encodings.items():\n",
    "    print(key)\n",
    "    print(val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(inputs)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# and move our model over to the selected device\n",
    "model.to(device)\n",
    "# activate training mode\n",
    "model.train()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "optim = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.8045, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   3%|▎         | 1/32 [01:50<57:02, 110.40s/it, loss=14.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.3474, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   6%|▋         | 2/32 [03:40<55:06, 110.21s/it, loss=11.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.6161, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   9%|▉         | 3/32 [05:24<52:22, 108.36s/it, loss=9.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.3105, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  12%|█▎        | 4/32 [07:13<50:41, 108.63s/it, loss=8.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.5944, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  16%|█▌        | 5/32 [08:59<48:34, 107.95s/it, loss=7.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5973, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  19%|█▉        | 6/32 [10:46<46:39, 107.67s/it, loss=6.6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.2084, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  22%|██▏       | 7/32 [12:33<44:45, 107.41s/it, loss=6.21]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.7379, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  25%|██▌       | 8/32 [14:21<43:00, 107.54s/it, loss=5.74]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.1174, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  28%|██▊       | 9/32 [16:11<41:31, 108.33s/it, loss=5.12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5005, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  31%|███▏      | 10/32 [18:01<39:52, 108.73s/it, loss=4.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0221, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  34%|███▍      | 11/32 [19:55<38:37, 110.38s/it, loss=4.02]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6693, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  38%|███▊      | 12/32 [21:43<36:31, 109.59s/it, loss=3.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1024, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  41%|████      | 13/32 [23:31<34:34, 109.16s/it, loss=3.1] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8592, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  44%|████▍     | 14/32 [25:20<32:42, 109.04s/it, loss=2.86]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4726, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  47%|████▋     | 15/32 [27:07<30:46, 108.62s/it, loss=2.47]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2463, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 16/32 [28:53<28:45, 107.83s/it, loss=2.25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0031, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  53%|█████▎    | 17/32 [30:43<27:04, 108.28s/it, loss=2]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7557, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  56%|█████▋    | 18/32 [32:28<25:05, 107.51s/it, loss=1.76]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # for our progress bar\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "#         prediction_logits = outputs.last_hidden_state\n",
    "#         pooler_output = outputs.pooler_output\n",
    "\n",
    "#         print(prediction_logits.shape) # (batch_size, sequence_length, hidden_size)\n",
    "# #         print(pooler_output.shape) # ((batch_size, hidden_size)\n",
    "#         print(labels.shape) # (batch_size, sequence_length)\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        print(loss)\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
